{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前5个日期列: Index(['1998-01', '1998-02', '1998-03', '1998-04', '1998-05'], dtype='object')\n",
      "L=0,S=1,rou=50%时的QuantileLoss值：1.010971\n",
      "L=0,S=1,rou=50%时的QuantileLoss值：1.014479\n",
      "L=0,S=1,rou=50%时的QuantileLoss值：1.023553\n",
      "\n",
      "交叉验证结果:\n",
      "R2: -0.2901\n",
      "RMSE: 1.2685\n",
      "MAE: 0.6550\n",
      "Bias: -3089.4598\n",
      "RMSE_non_zero: 2.0639\n",
      "MAE_non_zero: 1.6605\n",
      "Precision_zero: 0.0000\n",
      "Recall_zero: 0.0000\n",
      "F1_zero: 0.0000\n",
      "QuantileLoss_50: 1.0163\n",
      "RMSE_0: 0.0569\n",
      "MAE_0: 0.0436\n",
      "RMSE_0_50: 2.0639\n",
      "MAE_0_50: 1.6605\n",
      "MASE: 0.7229\n",
      "RMSSE: 0.6598\n",
      "MASE_non_zero: 1.6811\n",
      "RMSSE_non_zero: 0.7401\n",
      "混淆矩阵:\n",
      " [[5833    0]\n",
      " [9593    0]]\n",
      "L=0,S=1,rou=50%时的QuantileLoss值：1.024572\n",
      "\n",
      "测试集评估结果:\n",
      "R2: -0.2264\n",
      "RMSE: 1.1937\n",
      "MAE: 0.5682\n",
      "Bias: -1758.3957\n",
      "RMSE_non_zero: 2.0869\n",
      "MAE_non_zero: 1.6545\n",
      "Precision_zero: 0.0000\n",
      "Recall_zero: 0.0000\n",
      "F1_zero: 0.0000\n",
      "QuantileLoss_50: 1.0246\n",
      "RMSE_0: 0.0525\n",
      "MAE_0: 0.0410\n",
      "RMSE_0_50: 2.0869\n",
      "MAE_0_50: 1.6545\n",
      "MASE: 0.5944\n",
      "RMSSE: 1.0536\n",
      "MASE_non_zero: 1.5987\n",
      "RMSSE_non_zero: 1.4563\n",
      "混淆矩阵:\n",
      " [[1120    0]\n",
      " [2308    0]]\n",
      "\n",
      "示例库存计划:\n",
      "21053055:\n",
      "  reorder_point: 2.00\n",
      "  safety_stock: 0.00\n",
      "  lead_time_demand: 2.00\n",
      "  demand_variance: 0.00\n",
      "  forecast: 0.01\n",
      "21091739:\n",
      "  reorder_point: 2.74\n",
      "  safety_stock: 0.74\n",
      "  lead_time_demand: 2.00\n",
      "  demand_variance: 0.12\n",
      "  forecast: 0.01\n",
      "21314374:\n",
      "  reorder_point: 2.72\n",
      "  safety_stock: 0.72\n",
      "  lead_time_demand: 2.00\n",
      "  demand_variance: 0.12\n",
      "  forecast: 0.02\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error,\n",
    "    precision_score, recall_score, f1_score, \n",
    "    r2_score, confusion_matrix\n",
    ")\n",
    "from scipy.stats import variation\n",
    "import warnings\n",
    "from gluonts.evaluation.metrics import quantile_loss\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "@dataclass\n",
    "class DRPSeriesState:\n",
    "    \"\"\"单条时间序列的状态跟踪\"\"\"\n",
    "    last_demand: float = 0\n",
    "    last_interval: float = 1\n",
    "    demand_var: float = 0\n",
    "    forecast: float = 0\n",
    "    demand_alpha: float = 0.1\n",
    "    interval_alpha: float = 0.1\n",
    "    lead_time: int = 1\n",
    "    safety_factor: float = 1.5\n",
    "    last_non_zero_idx: int = -1\n",
    "    demand_history: List[float] = None\n",
    "    interval_history: List[float] = None\n",
    "\n",
    "class DRPModel:\n",
    "    \"\"\"完整的DRP模型实现，包含所有指标计算\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 lead_time: int = 1,\n",
    "                 safety_factor: float = 1.5,\n",
    "                 demand_alpha: float = 0.1,\n",
    "                 interval_alpha: float = 0.1):\n",
    "        self.params = {\n",
    "            'lead_time': lead_time,\n",
    "            'safety_factor': safety_factor,\n",
    "            'demand_alpha': demand_alpha,\n",
    "            'interval_alpha': interval_alpha\n",
    "        }\n",
    "        self.series_states = {}\n",
    "    \n",
    "    def _safe_parse_date(self, date_str: str) -> Optional[datetime]:\n",
    "        \"\"\"安全解析日期，处理无效日期\"\"\"\n",
    "        try:\n",
    "            return parse(str(date_str))\n",
    "        except (ValueError, TypeError):\n",
    "            # 尝试处理常见的格式问题\n",
    "            if str(date_str).count('-') == 2:\n",
    "                parts = str(date_str).split('-')\n",
    "                try:\n",
    "                    # 尝试将日期调整为有效日期（如将2月30日改为28日）\n",
    "                    fixed_date = f\"{parts[0]}-{parts[1]}-28\"\n",
    "                    return parse(fixed_date)\n",
    "                except:\n",
    "                    return None\n",
    "            return None\n",
    "    \n",
    "    def fit(self, df: pd.DataFrame) -> Dict[str, DRPSeriesState]:\n",
    "        \"\"\"拟合模型到训练数据\"\"\"\n",
    "        # 处理日期列\n",
    "        date_strs = df.columns.astype(str).tolist()\n",
    "        valid_dates = []\n",
    "        date_indices = []\n",
    "        \n",
    "        for i, d in enumerate(date_strs):\n",
    "            dt = self._safe_parse_date(d)\n",
    "            if dt is not None:\n",
    "                valid_dates.append(dt)\n",
    "                date_indices.append(i)\n",
    "        \n",
    "        if not valid_dates:\n",
    "            raise ValueError(\"没有有效的日期列，请检查数据格式\")\n",
    "        \n",
    "        for part_id, series in df.iterrows():\n",
    "            state = DRPSeriesState(\n",
    "                **self.params,\n",
    "                demand_history=[],\n",
    "                interval_history=[]\n",
    "            )\n",
    "            \n",
    "            # 获取非零需求点\n",
    "            non_zero_mask = series > 0\n",
    "            non_zero_values = series[non_zero_mask].values\n",
    "            non_zero_dates = [valid_dates[i] for i in np.where(non_zero_mask)[0] if i in date_indices]\n",
    "            \n",
    "            if len(non_zero_values) < 2:\n",
    "                self.series_states[part_id] = state\n",
    "                continue\n",
    "                \n",
    "            # 初始化状态\n",
    "            state.last_demand = non_zero_values[0]\n",
    "            state.demand_history.append(state.last_demand)\n",
    "            \n",
    "            # 计算间隔\n",
    "            intervals = []\n",
    "            for i in range(1, len(non_zero_dates)):\n",
    "                delta = (non_zero_dates[i] - non_zero_dates[i-1]).days\n",
    "                intervals.append(delta)\n",
    "            \n",
    "            if intervals:\n",
    "                state.interval_history = intervals\n",
    "                state.last_interval = np.mean(intervals)\n",
    "            \n",
    "            # 计算方差\n",
    "            if len(non_zero_values) > 1:\n",
    "                state.demand_var = np.var(non_zero_values)\n",
    "            \n",
    "            self.series_states[part_id] = state\n",
    "        \n",
    "        return self.series_states\n",
    "    \n",
    "    def predict(self, part_ids: List[str], horizon: int = 1) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"为多个时间序列生成预测\"\"\"\n",
    "        forecasts = {}\n",
    "        for part_id in part_ids:\n",
    "            if part_id not in self.series_states:\n",
    "                forecasts[part_id] = np.zeros(horizon)\n",
    "                continue\n",
    "                \n",
    "            state = self.series_states[part_id]\n",
    "            forecast_value = state.last_demand / state.last_interval if state.last_interval > 0 else 0\n",
    "            forecasts[part_id] = np.full(horizon, forecast_value)\n",
    "        \n",
    "        return forecasts\n",
    "    \n",
    "    def get_inventory_plans(self, part_ids: List[str]) -> Dict[str, Dict]:\n",
    "        \"\"\"获取库存计划参数\"\"\"\n",
    "        plans = {}\n",
    "        for part_id in part_ids:\n",
    "            if part_id not in self.series_states:\n",
    "                plans[part_id] = None\n",
    "                continue\n",
    "                \n",
    "            state = self.series_states[part_id]\n",
    "            lead_time_demand = state.last_demand * state.lead_time\n",
    "            safety_stock = state.safety_factor * np.sqrt(max(0, state.demand_var)) * np.sqrt(state.lead_time)\n",
    "            \n",
    "            plans[part_id] = {\n",
    "                'reorder_point': max(0, lead_time_demand + safety_stock),\n",
    "                'safety_stock': safety_stock,\n",
    "                'lead_time_demand': lead_time_demand,\n",
    "                'demand_variance': state.demand_var,\n",
    "                'forecast': state.last_demand / state.last_interval if state.last_interval > 0 else 0\n",
    "            }\n",
    "        \n",
    "        return plans\n",
    "\n",
    "class DRPEvaluator:\n",
    "    \"\"\"完整的评估器，包含所有指标\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean_absolute_scaled_error(y_true: np.ndarray, y_pred: np.ndarray, y_train: np.ndarray) -> float:\n",
    "        scaling_factor = np.mean(np.abs(np.diff(y_train)))\n",
    "        return np.mean(np.abs(y_true - y_pred)) / scaling_factor if scaling_factor > 0 else np.nan\n",
    "    \n",
    "    @staticmethod\n",
    "    def root_mean_square_scaled_error(y_true: np.ndarray, y_pred: np.ndarray, y_train: np.ndarray) -> float:\n",
    "        scaling_factor = np.mean(np.square(np.diff(y_train)))\n",
    "        return np.sqrt(np.mean(np.square(y_true - y_pred)) / scaling_factor) if scaling_factor > 0 else np.nan\n",
    "    \n",
    "    @staticmethod\n",
    "    def quantile_loss(y_true: np.ndarray, y_pred: np.ndarray, q: float) -> float:\n",
    "        errors = y_true - y_pred\n",
    "        return np.mean(np.maximum(q * errors, (q - 1) * errors))\n",
    "    \n",
    "    @staticmethod\n",
    "    def bias_amount(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        return np.sum(y_pred) - np.sum(y_true)\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmsse(y_true: np.ndarray, y_pred: np.ndarray, y_train: np.ndarray, h: int = 1) -> float:\n",
    "        numerator = np.sum(np.square(y_true - y_pred))\n",
    "        denominator = np.mean(np.square(np.diff(y_train)))\n",
    "        return np.sqrt(numerator / (denominator * h)) if denominator > 0 else np.nan\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate(\n",
    "        y_true: Dict[str, np.ndarray],\n",
    "        y_pred: Dict[str, np.ndarray],\n",
    "        y_train: Dict[str, np.ndarray],\n",
    "        test_month_num: int = 1\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"计算全部指标\"\"\"\n",
    "        # 合并所有序列\n",
    "        true_all = np.concatenate(list(y_true.values()))\n",
    "        pred_all = np.concatenate(list(y_pred.values()))\n",
    "        \n",
    "        # 基础指标\n",
    "        metrics = {\n",
    "            'R2': r2_score(true_all, pred_all),\n",
    "            'RMSE': mean_squared_error(true_all, pred_all, squared=False),\n",
    "            'MAE': mean_absolute_error(true_all, pred_all),\n",
    "            'Bias': DRPEvaluator.bias_amount(true_all, pred_all)\n",
    "        }\n",
    "        \n",
    "        # 非零指标\n",
    "        non_zero_mask = true_all > 0\n",
    "        if np.any(non_zero_mask):\n",
    "            metrics.update({\n",
    "                'RMSE_non_zero': mean_squared_error(true_all[non_zero_mask], pred_all[non_zero_mask], squared=False),\n",
    "                'MAE_non_zero': mean_absolute_error(true_all[non_zero_mask], pred_all[non_zero_mask])\n",
    "            })\n",
    "        \n",
    "        # 零值指标\n",
    "        zero_mask = true_all == 0\n",
    "        if np.any(zero_mask):\n",
    "            zero_pred = pred_all == 0\n",
    "            cm = confusion_matrix(zero_mask, zero_pred)\n",
    "            metrics.update({\n",
    "                'Precision_zero': precision_score(zero_mask, zero_pred, zero_division=0),\n",
    "                'Recall_zero': recall_score(zero_mask, zero_pred, zero_division=0),\n",
    "                'F1_zero': f1_score(zero_mask, zero_pred, zero_division=0),\n",
    "                'Confusion_Matrix': cm\n",
    "            })\n",
    "        \n",
    "        # 分位数损失\n",
    "        ##QuantileLoss指标\n",
    "        testmonth_num = 1\n",
    "        LS_list = [(0,1)]  #L表示相对于第1个预测时间t0的QuantileLoss区间起始点，S表示QuantileLoss区间长度\n",
    "        for LS_pair in LS_list:\n",
    "            L = LS_pair[0]\n",
    "            S = LS_pair[1]\n",
    "            QuantileLoss2 = 0.0\n",
    "            test_y2 = 0.0\n",
    "            num = int(len(pred_all) / testmonth_num)  ##时间序列sku数量\n",
    "            for i in range(num):\n",
    "                QuantileLoss2 += quantile_loss(true_all[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                              pred_all[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                              q=0.5)\n",
    "                test_y2 += np.sum(true_all[(testmonth_num * i + L):(testmonth_num * i + L + S)])\n",
    "            #print(QuantileLoss2,test_y2)\n",
    "            QuantileLoss2 = QuantileLoss2 / test_y2\n",
    "            print('L=%d,S=%d,rou=50%%时的QuantileLoss值：%f' % (L,S,QuantileLoss2))\n",
    "            metrics[f'QuantileLoss_50'] = QuantileLoss2\n",
    "\n",
    "        '''\n",
    "        if np.sum(true_all) > 0:\n",
    "            for q in [0.1, 0.5, 0.9]:\n",
    "                metrics[f'QuantileLoss_{int(q*100)}'] = DRPEvaluator.quantile_loss(true_all, pred_all, q)\n",
    "        '''\n",
    "        # 分段评估\n",
    "        segments = {\n",
    "            '0': (0, 0),\n",
    "            '0_50': (0.1, 50),\n",
    "            '50_100': (50, 100),\n",
    "            '100+': (100, np.inf)\n",
    "        }\n",
    "        \n",
    "        for seg_name, (low, high) in segments.items():\n",
    "            if low == 0 and high == 0:\n",
    "                mask = true_all == 0\n",
    "            else:\n",
    "                mask = (true_all > low) & (true_all <= high)\n",
    "            \n",
    "            if np.sum(mask) > 0:\n",
    "                metrics.update({\n",
    "                    f'RMSE_{seg_name}': mean_squared_error(true_all[mask], pred_all[mask], squared=False),\n",
    "                    f'MAE_{seg_name}': mean_absolute_error(true_all[mask], pred_all[mask])\n",
    "                })\n",
    "        \n",
    "        # 计算MASE和RMSSE（按序列计算后取平均）\n",
    "        mase_values = []\n",
    "        rmsse_values = []\n",
    "        mase_nz_values = []\n",
    "        rmsse_nz_values = []\n",
    "        \n",
    "        for part_id in y_true:\n",
    "            y_t = y_true[part_id]\n",
    "            y_p = y_pred[part_id]\n",
    "            y_tr = y_train[part_id]\n",
    "            \n",
    "            # 总体指标\n",
    "            mase = DRPEvaluator.mean_absolute_scaled_error(y_t, y_p, y_tr)\n",
    "            rmsse = DRPEvaluator.rmsse(y_t, y_p, y_tr, test_month_num)\n",
    "            if not np.isnan(mase):\n",
    "                mase_values.append(mase)\n",
    "            if not np.isnan(rmsse):\n",
    "                rmsse_values.append(rmsse)\n",
    "            \n",
    "            # 非零指标\n",
    "            nz_mask = y_t > 0\n",
    "            if np.any(nz_mask):\n",
    "                mase_nz = DRPEvaluator.mean_absolute_scaled_error(y_t[nz_mask], y_p[nz_mask], y_tr)\n",
    "                rmsse_nz = DRPEvaluator.rmsse(y_t[nz_mask], y_p[nz_mask], y_tr, test_month_num)\n",
    "                if not np.isnan(mase_nz):\n",
    "                    mase_nz_values.append(mase_nz)\n",
    "                if not np.isnan(rmsse_nz):\n",
    "                    rmsse_nz_values.append(rmsse_nz)\n",
    "        \n",
    "        metrics.update({\n",
    "            'MASE': np.mean(mase_values) if mase_values else np.nan,\n",
    "            'RMSSE': np.mean(rmsse_values) if rmsse_values else np.nan,\n",
    "            'MASE_non_zero': np.mean(mase_nz_values) if mase_nz_values else np.nan,\n",
    "            'RMSSE_non_zero': np.mean(rmsse_nz_values) if rmsse_nz_values else np.nan\n",
    "        })\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "def time_series_cross_validate(\n",
    "    df: pd.DataFrame,\n",
    "    model_class,\n",
    "    n_splits: int = 5,\n",
    "    horizon: int = 12,\n",
    "    **model_params\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"时间序列交叉验证\"\"\"\n",
    "    all_metrics = []\n",
    "    n_periods = df.shape[1]\n",
    "    test_size = horizon\n",
    "    train_size = n_periods - test_size * n_splits\n",
    "    \n",
    "    if train_size <= 0:\n",
    "        raise ValueError(\"交叉验证设置不合理：n_splits * horizon 大于总时间长度\")\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        train_end = train_size + i * test_size\n",
    "        test_end = min(train_end + test_size, n_periods)\n",
    "        \n",
    "        train_df = df.iloc[:, :train_end]\n",
    "        test_df = df.iloc[:, train_end:test_end]\n",
    "        \n",
    "        # 训练模型\n",
    "        model = model_class(**model_params)\n",
    "        model.fit(train_df)\n",
    "        \n",
    "        # 预测\n",
    "        preds = model.predict(test_df.index.tolist(), horizon=test_size)\n",
    "        \n",
    "        # 准备评估数据\n",
    "        y_true = {k: v.values for k, v in test_df.iterrows()}\n",
    "        y_train = {k: v.values for k, v in train_df.iterrows()}\n",
    "        \n",
    "        # 评估\n",
    "        metrics = DRPEvaluator.evaluate(y_true, preds, y_train, test_month_num=horizon)\n",
    "        all_metrics.append(metrics)\n",
    "    \n",
    "    # 聚合结果\n",
    "    final_metrics = {}\n",
    "    for metric in all_metrics[0].keys():\n",
    "        if metric == 'Confusion_Matrix':\n",
    "            final_metrics[metric] = sum([m[metric] for m in all_metrics])\n",
    "        else:\n",
    "            values = [m[metric] for m in all_metrics if not np.isnan(m[metric])]\n",
    "            final_metrics[metric] = np.mean(values) if values else np.nan\n",
    "    \n",
    "    return final_metrics\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据\n",
    "    # 加载数据(确保第一列是Part ID，后面是日期列)\n",
    "    #data = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\InterSim层次聚类后的Q料202001-202302(halfmonth).csv', index_col=0)\n",
    "    #data = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\salestv_data.csv', index_col=0)\n",
    "    data = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\carpartsdelete70.csv', index_col=0)\n",
    "        #将列名转化为202001 ~ 202604月份，避免freq=15d的2-30日期问题\n",
    "    import calendar\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    date_str = '1998-01'\n",
    "    date_format = '%Y-%m'\n",
    "    num_months = 51 #51 76 1913\n",
    "\n",
    "    dates = []\n",
    "    current_date = datetime.strptime(date_str, date_format)\n",
    "\n",
    "    for i in range(num_months):\n",
    "        dates.append(current_date.strftime(date_format))\n",
    "        num_days = calendar.monthrange(current_date.year, current_date.month)[1]\n",
    "        current_date += timedelta(days=num_days)\n",
    "\n",
    "    data.columns = dates\n",
    "    \n",
    "    \n",
    "    # 检查日期列\n",
    "    print(\"前5个日期列:\", data.columns[:5])\n",
    "    \n",
    "    # 运行交叉验证\n",
    "    cv_results = time_series_cross_validate(\n",
    "        data,\n",
    "        DRPModel,\n",
    "        n_splits=3,\n",
    "        horizon=6,\n",
    "        lead_time=2,\n",
    "        safety_factor=1.5,\n",
    "        demand_alpha=0.1,\n",
    "        interval_alpha=0.1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n交叉验证结果:\")\n",
    "    for metric, value in cv_results.items():\n",
    "        if metric != 'Confusion_Matrix':\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    print(\"混淆矩阵:\\n\", cv_results['Confusion_Matrix'])\n",
    "    \n",
    "    # 完整训练和评估\n",
    "    train_size = 47 #47 72 1909\n",
    "    train_df = data.iloc[:, :train_size]\n",
    "    test_df = data.iloc[:, train_size:]\n",
    "    \n",
    "    model = DRPModel(\n",
    "        lead_time=2,\n",
    "        safety_factor=1.5,\n",
    "        demand_alpha=0.1,\n",
    "        interval_alpha=0.1\n",
    "    )\n",
    "    model.fit(train_df)\n",
    "    \n",
    "    # 预测\n",
    "    preds = model.predict(test_df.index.tolist(), horizon=test_df.shape[1])\n",
    "    \n",
    "    # 评估\n",
    "    y_true = {k: v.values for k, v in test_df.iterrows()}\n",
    "    y_train = {k: v.values for k, v in train_df.iterrows()}\n",
    "    metrics = DRPEvaluator.evaluate(y_true, preds, y_train)\n",
    "    \n",
    "    print(\"\\n测试集评估结果:\")\n",
    "    for metric, value in metrics.items():\n",
    "        if metric != 'Confusion_Matrix':\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    print(\"混淆矩阵:\\n\", metrics['Confusion_Matrix'])\n",
    "    \n",
    "    # 查看库存计划\n",
    "    inventory_plans = model.get_inventory_plans(test_df.index.tolist()[:3])\n",
    "    print(\"\\n示例库存计划:\")\n",
    "    for part_id, plan in inventory_plans.items():\n",
    "        print(f\"{part_id}:\")\n",
    "        for k, v in plan.items():\n",
    "            print(f\"  {k}: {v:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation results:\n",
      "R2: -0.0920\n",
      "RMSE: 132.3085\n",
      "RMSE_non_zero: 205.5562\n",
      "MAE: 62.0869\n",
      "MAE_non_zero: 101.8514\n",
      "MASE: 2.2304\n",
      "MASE_non_zero: 4.5942\n",
      "RMSSE: 0.8999\n",
      "RMSSE_non_zero: 1.5241\n",
      "QuantileLoss_50: 1.6486\n",
      "Precision: 0.3515\n",
      "Recall: 0.0314\n",
      "F1: 0.0575\n",
      "MAE_0: 42.5108\n",
      "RMSE_0: 73.2039\n",
      "MAE_0_50: 41.9826\n",
      "RMSE_0_50: 67.8455\n",
      "MAE_50_100: 73.7444\n",
      "RMSE_50_100: 101.9926\n",
      "MAE_100_above: 204.4245\n",
      "RMSE_100_above: 339.4169\n",
      "\n",
      "Test set evaluation:\n",
      "R2: -2.6924\n",
      "RMSE: 89.2705\n",
      "RMSE_non_zero: 113.3447\n",
      "MAE: 52.1896\n",
      "MAE_non_zero: 74.7085\n",
      "MASE: 1.1239\n",
      "MASE_non_zero: 3.0165\n",
      "RMSSE: 0.5504\n",
      "RMSSE_non_zero: 1.1822\n",
      "QuantileLoss_50: 3.3219\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "MAE_0: 45.9879\n",
      "RMSE_0: 81.3995\n",
      "MAE_0_50: 46.4944\n",
      "RMSE_0_50: 79.2846\n",
      "MAE_50_100: 80.5397\n",
      "RMSE_50_100: 117.1014\n",
      "MAE_100_above: 137.8428\n",
      "RMSE_100_above: 167.7411\n",
      "\n",
      "Sample inventory plans:\n",
      "SKU 0:\n",
      "  reorder_point: 557.60\n",
      "  safety_stock: 168.27\n",
      "  lead_time_demand: 389.33\n",
      "  demand_variance: 6292.46\n",
      "  forecast: 95.24\n",
      "SKU 1:\n",
      "  reorder_point: 1162.86\n",
      "  safety_stock: 177.79\n",
      "  lead_time_demand: 985.06\n",
      "  demand_variance: 7024.51\n",
      "  forecast: 81.02\n",
      "SKU 2:\n",
      "  reorder_point: 852.88\n",
      "  safety_stock: 430.16\n",
      "  lead_time_demand: 422.71\n",
      "  demand_variance: 41119.90\n",
      "  forecast: 125.98\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from scipy.stats import variation\n",
    "import warnings\n",
    "from gluonts.evaluation.metrics import quantile_loss\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error,\n",
    "    precision_score, recall_score, f1_score, \n",
    "    r2_score, confusion_matrix\n",
    ")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "@dataclass\n",
    "class DRPResult:\n",
    "    \"\"\"Result container similar to CrostonResult\"\"\"\n",
    "    forecast: np.ndarray\n",
    "    demand_series: np.ndarray\n",
    "    interval_series: np.ndarray\n",
    "    alpha: float\n",
    "    initial_demand: float\n",
    "    initial_interval: float\n",
    "\n",
    "class DRPModel:\n",
    "    \"\"\"DRP model implementation aligned with Croston's interface\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 lead_time: int = 1,\n",
    "                 safety_factor: float = 1.5,\n",
    "                 alpha: float = 0.1):\n",
    "        self.lead_time = lead_time\n",
    "        self.safety_factor = safety_factor\n",
    "        self.alpha = alpha\n",
    "        self.fitted_models = []\n",
    "    \n",
    "    def _safe_parse_date(self, date_str: str) -> Optional[datetime]:\n",
    "        \"\"\"Safely parse dates, handling invalid dates\"\"\"\n",
    "        try:\n",
    "            return parse(str(date_str))\n",
    "        except (ValueError, TypeError):\n",
    "            if str(date_str).count('-') == 2:\n",
    "                parts = str(date_str).split('-')\n",
    "                try:\n",
    "                    fixed_date = f\"{parts[0]}-{parts[1]}-28\"\n",
    "                    return parse(fixed_date)\n",
    "                except:\n",
    "                    return None\n",
    "            return None\n",
    "    \n",
    "    def fit(self, data: pd.DataFrame) -> List[DRPResult]:\n",
    "        \"\"\"Fit model to training data, returning DRPResult objects\"\"\"\n",
    "        date_strs = data.columns.astype(str).tolist()\n",
    "        valid_dates = []\n",
    "        date_indices = []\n",
    "        \n",
    "        for i, d in enumerate(date_strs):\n",
    "            dt = self._safe_parse_date(d)\n",
    "            if dt is not None:\n",
    "                valid_dates.append(dt)\n",
    "                date_indices.append(i)\n",
    "        \n",
    "        if not valid_dates:\n",
    "            raise ValueError(\"No valid date columns found\")\n",
    "        \n",
    "        results = []\n",
    "        for series in data.values:\n",
    "            non_zero_indices = np.where(series > 0)[0]\n",
    "            valid_non_zero_indices = [i for i in non_zero_indices if i in date_indices]\n",
    "            \n",
    "            if len(valid_non_zero_indices) == 0:\n",
    "                results.append(DRPResult(\n",
    "                    forecast=np.zeros(len(series)),\n",
    "                    demand_series=np.zeros(len(series)),\n",
    "                    interval_series=np.zeros(len(series)),\n",
    "                    alpha=self.alpha,\n",
    "                    initial_demand=0,\n",
    "                    initial_interval=0\n",
    "                ))\n",
    "                continue\n",
    "                \n",
    "            # Extract demand and intervals\n",
    "            demand = series[valid_non_zero_indices]\n",
    "            intervals = np.diff(valid_non_zero_indices, prepend=-1)\n",
    "            intervals[0] = valid_non_zero_indices[0] + 1  # Handle first interval\n",
    "            \n",
    "            # Initialize series\n",
    "            demand_series = np.zeros(len(series))\n",
    "            interval_series = np.zeros(len(series))\n",
    "            \n",
    "            # Initial values\n",
    "            initial_demand = demand[0]\n",
    "            initial_interval = intervals[0]\n",
    "            \n",
    "            # Update series\n",
    "            current_demand = initial_demand\n",
    "            current_interval = initial_interval\n",
    "            last_non_zero_idx = valid_non_zero_indices[0]\n",
    "            \n",
    "            for i in range(len(series)):\n",
    "                if series[i] > 0 and i in date_indices:\n",
    "                    current_demand = self.alpha * series[i] + (1 - self.alpha) * current_demand\n",
    "                    if i > 0:\n",
    "                        prev_non_zero = [x for x in valid_non_zero_indices if x < i]\n",
    "                        if prev_non_zero:\n",
    "                            interval = i - prev_non_zero[-1]\n",
    "                        else:\n",
    "                            interval = i + 1\n",
    "                        current_interval = self.alpha * interval + (1 - self.alpha) * current_interval\n",
    "                        last_non_zero_idx = i\n",
    "                \n",
    "                demand_series[i] = current_demand\n",
    "                interval_series[i] = current_interval\n",
    "            \n",
    "            # Calculate forecasts\n",
    "            forecast = np.where(interval_series > 0, demand_series / interval_series, 0)\n",
    "            \n",
    "            results.append(DRPResult(\n",
    "                forecast=forecast,\n",
    "                demand_series=demand_series,\n",
    "                interval_series=interval_series,\n",
    "                alpha=self.alpha,\n",
    "                initial_demand=initial_demand,\n",
    "                initial_interval=initial_interval\n",
    "            ))\n",
    "        \n",
    "        self.fitted_models = results\n",
    "        return results\n",
    "    \n",
    "    def predict(self, steps: int = 1) -> np.ndarray:\n",
    "        \"\"\"Predict future values\"\"\"\n",
    "        forecasts = []\n",
    "        for model in self.fitted_models:\n",
    "            last_demand = model.demand_series[-1]\n",
    "            last_interval = model.interval_series[-1]\n",
    "            \n",
    "            if last_interval <= 0:\n",
    "                forecasts.append(np.zeros(steps))\n",
    "            else:\n",
    "                forecasts.append(np.full(steps, last_demand / last_interval))\n",
    "        \n",
    "        return np.array(forecasts)\n",
    "    \n",
    "    def get_inventory_plans(self) -> List[Dict]:\n",
    "        \"\"\"Get inventory plans for all series\"\"\"\n",
    "        plans = []\n",
    "        for model in self.fitted_models:\n",
    "            demand_var = np.var(model.demand_series[model.demand_series > 0]) if np.any(model.demand_series > 0) else 0\n",
    "            lead_time_demand = model.demand_series[-1] * self.lead_time\n",
    "            safety_stock = self.safety_factor * np.sqrt(max(0, demand_var)) * np.sqrt(self.lead_time)\n",
    "            \n",
    "            plans.append({\n",
    "                'reorder_point': max(0, lead_time_demand + safety_stock),\n",
    "                'safety_stock': safety_stock,\n",
    "                'lead_time_demand': lead_time_demand,\n",
    "                'demand_variance': demand_var,\n",
    "                'forecast': model.demand_series[-1] / model.interval_series[-1] if model.interval_series[-1] > 0 else 0\n",
    "            })\n",
    "        \n",
    "        return plans\n",
    "\n",
    "\n",
    "class DRPEvaluator:\n",
    "    \"\"\"Evaluator using same metrics as CrostonEvaluator\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean_absolute_scaled_error(y_true: np.ndarray, y_pred: np.ndarray, y_train: np.ndarray) -> float:\n",
    "        scaling_factor = np.mean(np.abs(np.diff(y_train)))\n",
    "        return np.mean(np.abs(y_true - y_pred)) / scaling_factor if scaling_factor > 0 else np.nan\n",
    "    \n",
    "    @staticmethod\n",
    "    def root_mean_square_scaled_error(y_true: np.ndarray, y_pred: np.ndarray, y_train: np.ndarray) -> float:\n",
    "        scaling_factor = np.mean(np.square(np.diff(y_train)))\n",
    "        return np.sqrt(np.mean(np.square(y_true - y_pred)) / scaling_factor) if scaling_factor > 0 else np.nan\n",
    "    \n",
    "    @staticmethod\n",
    "    def quantile_loss(y_true: np.ndarray, y_pred: np.ndarray, q: float) -> float:\n",
    "        errors = y_true - y_pred\n",
    "        return np.mean(np.maximum(q * errors, (q - 1) * errors))\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate(\n",
    "        y_true: np.ndarray,\n",
    "        y_pred: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        test_month_num: int = 1\n",
    "    ) -> dict:\n",
    "        metrics = {}\n",
    "        y_true_flat = y_true.flatten()\n",
    "        y_pred_flat = y_pred.flatten()\n",
    "        \n",
    "        # Non-zero metrics\n",
    "        non_zero_mask = y_true_flat > 0\n",
    "        y_true_non_zero = y_true_flat[non_zero_mask]\n",
    "        y_pred_non_zero = y_pred_flat[non_zero_mask]\n",
    "        \n",
    "        # R2 score\n",
    "        metrics['R2'] = r2_score(y_true_flat, y_pred_flat)\n",
    "        \n",
    "        # RMSE\n",
    "        metrics['RMSE'] = mean_squared_error(y_true_flat, y_pred_flat, squared=False)\n",
    "        metrics['RMSE_non_zero'] = mean_squared_error(y_true_non_zero, y_pred_non_zero, squared=False) if len(y_true_non_zero) > 0 else np.nan\n",
    "        \n",
    "        # MAE\n",
    "        metrics['MAE'] = mean_absolute_error(y_true_flat, y_pred_flat)\n",
    "        metrics['MAE_non_zero'] = mean_absolute_error(y_true_non_zero, y_pred_non_zero) if len(y_true_non_zero) > 0 else np.nan\n",
    "        \n",
    "        # MASE\n",
    "        mase_values = []\n",
    "        mase_non_zero_values = []\n",
    "        for i in range(len(y_true)):\n",
    "            mase = DRPEvaluator.mean_absolute_scaled_error(y_true[i], y_pred[i], y_train[i])\n",
    "            mase_values.append(mase)\n",
    "            \n",
    "            # Non-zero MASE\n",
    "            non_zero_mask = y_true[i] > 0\n",
    "            if np.any(non_zero_mask):\n",
    "                mase_nz = DRPEvaluator.mean_absolute_scaled_error(\n",
    "                    y_true[i][non_zero_mask], \n",
    "                    y_pred[i][non_zero_mask], \n",
    "                    y_train[i]\n",
    "                )\n",
    "                mase_non_zero_values.append(mase_nz)\n",
    "        \n",
    "        metrics['MASE'] = np.nanmean(mase_values)\n",
    "        metrics['MASE_non_zero'] = np.nanmean(mase_non_zero_values) if mase_non_zero_values else np.nan\n",
    "        \n",
    "        # RMSSE\n",
    "        rmsse_values = []\n",
    "        rmsse_non_zero_values = []\n",
    "        for i in range(len(y_true)):\n",
    "            rmsse = DRPEvaluator.root_mean_square_scaled_error(y_true[i], y_pred[i], y_train[i])\n",
    "            rmsse_values.append(rmsse)\n",
    "            \n",
    "            # Non-zero RMSSE\n",
    "            non_zero_mask = y_true[i] > 0\n",
    "            if np.any(non_zero_mask):\n",
    "                rmsse_nz = DRPEvaluator.root_mean_square_scaled_error(\n",
    "                    y_true[i][non_zero_mask], \n",
    "                    y_pred[i][non_zero_mask], \n",
    "                    y_train[i]\n",
    "                )\n",
    "                rmsse_non_zero_values.append(rmsse_nz)\n",
    "        \n",
    "        metrics['RMSSE'] = np.nanmean(rmsse_values)\n",
    "        metrics['RMSSE_non_zero'] = np.nanmean(rmsse_non_zero_values) if rmsse_non_zero_values else np.nan\n",
    "        \n",
    "        # Quantile Loss\n",
    "        testmonth_num = 1\n",
    "        LS_list = [(0,1)]\n",
    "        for LS_pair in LS_list:\n",
    "            L = LS_pair[0]\n",
    "            S = LS_pair[1]\n",
    "            QuantileLoss2 = 0.0\n",
    "            test_y2 = 0.0\n",
    "            num = int(len(y_pred_flat) / testmonth_num)\n",
    "            for i in range(num):\n",
    "                QuantileLoss2 += quantile_loss(\n",
    "                    y_true_flat[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                    y_pred_flat[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                    q=0.5\n",
    "                )\n",
    "                test_y2 += np.sum(y_true_flat[(testmonth_num * i + L):(testmonth_num * i + L + S)])\n",
    "            QuantileLoss2 = QuantileLoss2 / test_y2\n",
    "            metrics[f'QuantileLoss_50'] = QuantileLoss2\n",
    "        \n",
    "        # Zero metrics\n",
    "        test_y_01 = [1 if x == 0 else 0 for x in y_true_flat]\n",
    "        test_predict_01 = [1 if x == 0 else 0 for x in y_pred_flat]\n",
    "        metrics['Precision'] = precision_score(test_y_01, test_predict_01)\n",
    "        metrics['Recall'] = recall_score(test_y_01, test_predict_01)\n",
    "        metrics['F1'] = f1_score(test_y_01, test_predict_01)\n",
    "        \n",
    "        # Segment metrics\n",
    "        segments = {\n",
    "            '0': (0, 0),\n",
    "            '0_50': (0, 50),\n",
    "            '50_100': (50, 100),\n",
    "            '100_above': (100, np.inf)\n",
    "        }\n",
    "        \n",
    "        for name, (lower, upper) in segments.items():\n",
    "            if lower == upper:\n",
    "                mask = y_true_flat == lower\n",
    "            elif upper == np.inf:\n",
    "                mask = y_true_flat > lower\n",
    "            else:\n",
    "                mask = (y_true_flat > lower) & (y_true_flat <= upper)\n",
    "                \n",
    "            y_true_seg = y_true_flat[mask]\n",
    "            y_pred_seg = y_pred_flat[mask]\n",
    "            \n",
    "            if len(y_true_seg) > 0:\n",
    "                metrics[f'MAE_{name}'] = mean_absolute_error(y_true_seg, y_pred_seg)\n",
    "                metrics[f'RMSE_{name}'] = mean_squared_error(y_true_seg, y_pred_seg, squared=False)\n",
    "            else:\n",
    "                metrics[f'MAE_{name}'] = np.nan\n",
    "                metrics[f'RMSE_{name}'] = np.nan\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "def time_series_cross_validate(\n",
    "    df: pd.DataFrame,\n",
    "    model_class,\n",
    "    n_splits: int = 5,\n",
    "    horizon: int = 12,\n",
    "    **model_params\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"Time series cross validation\"\"\"\n",
    "    all_metrics = []\n",
    "    n_periods = df.shape[1]\n",
    "    test_size = horizon\n",
    "    train_size = n_periods - test_size * n_splits\n",
    "    \n",
    "    if train_size <= 0:\n",
    "        raise ValueError(\"Invalid CV setup: n_splits * horizon > total periods\")\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        train_end = train_size + i * test_size\n",
    "        test_end = min(train_end + test_size, n_periods)\n",
    "        \n",
    "        train_df = df.iloc[:, :train_end]\n",
    "        test_df = df.iloc[:, train_end:test_end]\n",
    "        \n",
    "        # Train model\n",
    "        model = model_class(**model_params)\n",
    "        model.fit(train_df)\n",
    "        \n",
    "        # Predict\n",
    "        preds = model.predict(steps=test_size)\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = DRPEvaluator.evaluate(\n",
    "            test_df.values, \n",
    "            preds, \n",
    "            train_df.values, \n",
    "            test_month_num=horizon\n",
    "        )\n",
    "        all_metrics.append(metrics)\n",
    "    \n",
    "    # Aggregate results\n",
    "    final_metrics = {}\n",
    "    for metric in all_metrics[0].keys():\n",
    "        values = [m[metric] for m in all_metrics if not np.isnan(m[metric])]\n",
    "        final_metrics[metric] = np.mean(values) if values else np.nan\n",
    "    \n",
    "    return final_metrics\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据(确保第一列是Part ID，后面是日期列)\n",
    "    data = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\InterSim层次聚类后的Q料202001-202302(halfmonth).csv', index_col=0)\n",
    "    #data = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\salestv_data.csv', index_col=0)\n",
    "    #data = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\carpartsdelete80.csv', index_col=0)\n",
    "        #将列名转化为202001 ~ 202604月份，避免freq=15d的2-30日期问题\n",
    "    import calendar\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    date_str = '1998-01'\n",
    "    date_format = '%Y-%m'\n",
    "    num_months = 76 #51 76 1913\n",
    "\n",
    "    dates = []\n",
    "    current_date = datetime.strptime(date_str, date_format)\n",
    "\n",
    "    for i in range(num_months):\n",
    "        dates.append(current_date.strftime(date_format))\n",
    "        num_days = calendar.monthrange(current_date.year, current_date.month)[1]\n",
    "        current_date += timedelta(days=num_days)\n",
    "\n",
    "    data.columns = dates\n",
    "    # Run cross validation\n",
    "    cv_results = time_series_cross_validate(\n",
    "        data,\n",
    "        DRPModel,\n",
    "        n_splits=3,\n",
    "        horizon=6,\n",
    "        lead_time=2,\n",
    "        safety_factor=1.5,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nCross-validation results:\")\n",
    "    for metric, value in cv_results.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Full train and evaluation\n",
    "    train_size = 72\n",
    "    train_df = data.iloc[:, :train_size]\n",
    "    test_df = data.iloc[:, train_size:]\n",
    "    \n",
    "    model = DRPModel(\n",
    "        lead_time=2,\n",
    "        safety_factor=1.5,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    model.fit(train_df)\n",
    "    \n",
    "    # Predict\n",
    "    preds = model.predict(steps=test_df.shape[1])\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = DRPEvaluator.evaluate(test_df.values, preds, train_df.values)\n",
    "    \n",
    "    print(\"\\nTest set evaluation:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # View inventory plans\n",
    "    inventory_plans = model.get_inventory_plans()[:3]\n",
    "    print(\"\\nSample inventory plans:\")\n",
    "    for i, plan in enumerate(inventory_plans):\n",
    "        print(f\"SKU {i}:\")\n",
    "        for k, v in plan.items():\n",
    "            print(f\"  {k}: {v:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
