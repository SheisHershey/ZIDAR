{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ab827357a6ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;31m# Evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrostonEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;31m# Print metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-ab827357a6ff>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(y_true, y_pred, y_train, test_month_num)\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mQuantileLoss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mtest_y2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtestmonth_num\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m##时间序列sku数量\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 QuantileLoss2 += quantile_loss(test_y[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_y' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from scipy.stats import variation\n",
    "from gluonts.evaluation.metrics import quantile_loss\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, precision_score, recall_score, f1_score\n",
    "@dataclass\n",
    "class CrostonResult:\n",
    "    forecast: np.ndarray\n",
    "    demand_series: np.ndarray\n",
    "    interval_series: np.ndarray\n",
    "    alpha: float\n",
    "    initial_demand: float\n",
    "    initial_interval: float\n",
    "\n",
    "class CrostonModel:\n",
    "    \"\"\"\n",
    "    Croston's method for intermittent demand forecasting that can handle multiple time series.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.1):\n",
    "        \"\"\"\n",
    "        Initialize the Croston model.\n",
    "        \n",
    "        Args:\n",
    "            alpha: Smoothing parameter between 0 and 1\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def fit(self, data: np.ndarray) -> List[CrostonResult]:\n",
    "        \"\"\"\n",
    "        Fit the Croston model to multiple time series.\n",
    "\n",
    "        Args:\n",
    "            data: 2D array where each row is a time series\n",
    "\n",
    "        Returns:\n",
    "            List of CrostonResult objects containing the model state for each series\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for series in data:\n",
    "            non_zero_indices = np.where(series > 0)[0]\n",
    "\n",
    "            if len(non_zero_indices) == 0:\n",
    "                # Handle all-zero series\n",
    "                results.append(CrostonResult(\n",
    "                    forecast=np.zeros(len(series)),\n",
    "                    demand_series=np.zeros(len(series)),\n",
    "                    interval_series=np.zeros(len(series)),\n",
    "                    alpha=self.alpha,\n",
    "                    initial_demand=0,\n",
    "                    initial_interval=0\n",
    "                ))\n",
    "                continue\n",
    "\n",
    "            # Extract demand and intervals\n",
    "            demand = series[non_zero_indices]\n",
    "            intervals = np.diff(non_zero_indices, prepend=-1)\n",
    "            intervals[0] = non_zero_indices[0] + 1  # Handle first interval\n",
    "\n",
    "            # Initialize demand and interval series\n",
    "            demand_series = np.zeros(len(series))\n",
    "            interval_series = np.zeros(len(series))\n",
    "\n",
    "            # Initial values\n",
    "            initial_demand = demand[0]\n",
    "            initial_interval = intervals[0]\n",
    "\n",
    "            # Update series\n",
    "            current_demand = initial_demand\n",
    "            current_interval = initial_interval\n",
    "\n",
    "            last_non_zero_idx = non_zero_indices[0]\n",
    "\n",
    "            for i in range(len(series)):\n",
    "                if series[i] > 0:\n",
    "                    current_demand = self.alpha * series[i] + (1 - self.alpha) * current_demand\n",
    "                    if i > 0:\n",
    "                        # Find previous non-zero index\n",
    "                        prev_non_zero = np.where(series[:i] > 0)[0]\n",
    "                        if len(prev_non_zero) > 0:\n",
    "                            interval = i - prev_non_zero[-1]\n",
    "                        else:\n",
    "                            interval = i + 1  # Only current non-zero so far\n",
    "                        current_interval = self.alpha * interval + (1 - self.alpha) * current_interval\n",
    "                        last_non_zero_idx = i\n",
    "\n",
    "                demand_series[i] = current_demand\n",
    "                interval_series[i] = current_interval\n",
    "\n",
    "            # Calculate forecasts\n",
    "            forecast = np.where(interval_series > 0, demand_series / interval_series, 0)\n",
    "\n",
    "            results.append(CrostonResult(\n",
    "                forecast=forecast,\n",
    "                demand_series=demand_series,\n",
    "                interval_series=interval_series,\n",
    "                alpha=self.alpha,\n",
    "                initial_demand=initial_demand,\n",
    "                initial_interval=initial_interval\n",
    "            ))\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def predict(self, fitted_models: List[CrostonResult], steps: int = 1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict future values for multiple time series.\n",
    "        \n",
    "        Args:\n",
    "            fitted_models: List of fitted CrostonResult objects\n",
    "            steps: Number of steps ahead to forecast\n",
    "            \n",
    "        Returns:\n",
    "            2D array of forecasts (n_series x steps)\n",
    "        \"\"\"\n",
    "        forecasts = []\n",
    "        for model in fitted_models:\n",
    "            last_demand = model.demand_series[-1]\n",
    "            last_interval = model.interval_series[-1]\n",
    "            \n",
    "            if last_interval <= 0:\n",
    "                forecasts.append(np.zeros(steps))\n",
    "            else:\n",
    "                forecasts.append(np.full(steps, last_demand / last_interval))\n",
    "        \n",
    "        return np.array(forecasts)\n",
    "\n",
    "class CrostonEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluator for Croston model with all the requested metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean_absolute_scaled_error(y_true: np.ndarray, y_pred: np.ndarray, y_train: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate mean absolute scaled error (MASE).\n",
    "        \"\"\"\n",
    "        n = len(y_true)\n",
    "        scaling_factor = np.mean(np.abs(np.diff(y_train)))\n",
    "        errors = np.abs(y_true - y_pred) / scaling_factor\n",
    "        return np.mean(errors)\n",
    "    \n",
    "    @staticmethod\n",
    "    def root_mean_square_scaled_error(y_true: np.ndarray, y_pred: np.ndarray, y_train: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate root mean square scaled error (RMSSE).\n",
    "        \"\"\"\n",
    "        n = len(y_true)\n",
    "        scaling_factor = np.mean(np.square(np.diff(y_train)))\n",
    "        errors = np.square(y_true - y_pred) / scaling_factor\n",
    "        return np.sqrt(np.mean(errors))\n",
    "    \n",
    "    @staticmethod\n",
    "    def quantile_loss(y_true: np.ndarray, y_pred: np.ndarray, q: float = 0.5) -> float:\n",
    "        \"\"\"\n",
    "        Calculate quantile loss.\n",
    "        \"\"\"\n",
    "        errors = y_true - y_pred\n",
    "        return np.mean(np.maximum(q * errors, (q - 1) * errors))\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate(\n",
    "        y_true: np.ndarray,\n",
    "        y_pred: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        test_month_num: int = 1\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Comprehensive evaluation of forecasts.\n",
    "        \n",
    "        Args:\n",
    "            y_true: True values (n_series x n_timesteps)\n",
    "            y_pred: Predicted values (n_series x n_timesteps)\n",
    "            y_train: Training values (n_series x n_train_timesteps)\n",
    "            test_month_num: Number of test timesteps per series\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Flatten arrays for overall metrics\n",
    "        y_true_flat = y_true.flatten()\n",
    "        y_pred_flat = y_pred.flatten()\n",
    "        \n",
    "        # Non-zero metrics\n",
    "        non_zero_mask = y_true_flat > 0\n",
    "        y_true_non_zero = y_true_flat[non_zero_mask]\n",
    "        y_pred_non_zero = y_pred_flat[non_zero_mask]\n",
    "        \n",
    "        # R2 score\n",
    "        metrics['R2'] = r2_score(y_true_flat, y_pred_flat)\n",
    "        \n",
    "        # RMSE\n",
    "        metrics['RMSE'] = mean_squared_error(y_true_flat, y_pred_flat, squared=False)\n",
    "        metrics['RMSE_non_zero'] = mean_squared_error(y_true_non_zero, y_pred_non_zero, squared=False) if len(y_true_non_zero) > 0 else np.nan\n",
    "        \n",
    "        # MAE\n",
    "        metrics['MAE'] = mean_absolute_error(y_true_flat, y_pred_flat)\n",
    "        metrics['MAE_non_zero'] = mean_absolute_error(y_true_non_zero, y_pred_non_zero) if len(y_true_non_zero) > 0 else np.nan\n",
    "        \n",
    "        # MASE\n",
    "        mase_values = []\n",
    "        mase_non_zero_values = []\n",
    "        for i in range(len(y_true)):\n",
    "            y_true_i = y_true[i]\n",
    "            y_pred_i = y_pred[i]\n",
    "            y_train_i = y_train[i]\n",
    "            \n",
    "            mase = CrostonEvaluator.mean_absolute_scaled_error(y_true_i, y_pred_i, y_train_i)\n",
    "            mase_values.append(mase)\n",
    "            \n",
    "            # Non-zero MASE\n",
    "            non_zero_mask = y_true_i > 0\n",
    "            if np.any(non_zero_mask):\n",
    "                mase_nz = CrostonEvaluator.mean_absolute_scaled_error(\n",
    "                    y_true_i[non_zero_mask], \n",
    "                    y_pred_i[non_zero_mask], \n",
    "                    y_train_i\n",
    "                )\n",
    "                mase_non_zero_values.append(mase_nz)\n",
    "        \n",
    "        metrics['MASE'] = np.nanmean(mase_values)\n",
    "        metrics['MASE_non_zero'] = np.nanmean(mase_non_zero_values) if mase_non_zero_values else np.nan\n",
    "        \n",
    "        # RMSSE\n",
    "        rmsse_values = []\n",
    "        rmsse_non_zero_values = []\n",
    "        for i in range(len(y_true)):\n",
    "            y_true_i = y_true[i]\n",
    "            y_pred_i = y_pred[i]\n",
    "            y_train_i = y_train[i]\n",
    "            \n",
    "            rmsse = CrostonEvaluator.root_mean_square_scaled_error(y_true_i, y_pred_i, y_train_i)\n",
    "            rmsse_values.append(rmsse)\n",
    "            \n",
    "            # Non-zero RMSSE\n",
    "            non_zero_mask = y_true_i > 0\n",
    "            if np.any(non_zero_mask):\n",
    "                rmsse_nz = CrostonEvaluator.root_mean_square_scaled_error(\n",
    "                    y_true_i[non_zero_mask], \n",
    "                    y_pred_i[non_zero_mask], \n",
    "                    y_train_i\n",
    "                )\n",
    "                rmsse_non_zero_values.append(rmsse_nz)\n",
    "        \n",
    "        metrics['RMSSE'] = np.nanmean(rmsse_values)\n",
    "        metrics['RMSSE_non_zero'] = np.nanmean(rmsse_non_zero_values) if rmsse_non_zero_values else np.nan\n",
    "        \n",
    "        # Quantile Loss\n",
    "        testmonth_num = 1\n",
    "        LS_list = [(0,1)]  #L表示相对于第1个预测时间t0的QuantileLoss区间起始点，S表示QuantileLoss区间长度\n",
    "        for LS_pair in LS_list:\n",
    "            L = LS_pair[0]\n",
    "            S = LS_pair[1]\n",
    "            QuantileLoss2 = 0.0\n",
    "            test_y2 = 0.0\n",
    "            num = int(len(y_pred_flat) / testmonth_num)  ##时间序列sku数量\n",
    "            for i in range(num):\n",
    "                QuantileLoss2 += quantile_loss(y_true_flat[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                              y_pred_flat[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                              q=0.5)\n",
    "                test_y2 += np.sum(y_true_flat[(testmonth_num * i + L):(testmonth_num * i + L + S)])\n",
    "            #print(QuantileLoss2,test_y2)\n",
    "            QuantileLoss2 = QuantileLoss2 / test_y2\n",
    "            \n",
    "            print('L=%d,S=%d,rou=50%%时的QuantileLoss值：%f' % (L,S,QuantileLoss2))\n",
    "            metrics[f'QuantileLoss_50'] = QuantileLoss2\n",
    "        test_y_01 = [1 if x == 0 else 0 for x in y_true_flat] #0为正类，1为负类\n",
    "        test_predict_01 = [1 if x == 0 else 0 for x in y_pred_flat]\n",
    "        metrics['Precision'] = precision_score(test_y_01, test_predict_01)\n",
    "        metrics['Recall'] = recall_score(test_y_01, test_predict_01)\n",
    "        metrics['F1'] = f1_score(test_y_01, test_predict_01)\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        print(\"真实零值分布:\", np.unique(test_y_01, return_counts=True))\n",
    "        print(\"预测零值分布:\", np.unique(test_predict_01, return_counts=True))\n",
    "        print(\"混淆矩阵:\\n\", confusion_matrix(test_y_01, test_predict_01))\n",
    "        '''\n",
    "        # Zero metrics\n",
    "        y_true_01 = (y_true_flat == 0).astype(int)\n",
    "        y_pred_01 = (y_pred_flat == 0).astype(int)\n",
    "        \n",
    "        if len(np.unique(y_true_01)) > 1 and len(np.unique(y_pred_01)) > 1:\n",
    "            metrics['Precision'] = precision_score(y_true_01, y_pred_01)\n",
    "            metrics['Recall'] = recall_score(y_true_01, y_pred_01)\n",
    "            metrics['F1'] = f1_score(y_true_01, y_pred_01)\n",
    "        else:\n",
    "            metrics['Precision'] = np.nan\n",
    "            metrics['Recall'] = np.nan\n",
    "            metrics['F1'] = np.nan\n",
    "        '''\n",
    "        # Segment metrics\n",
    "        segment_metrics = CrostonEvaluator.segment_evaluation(y_true_flat, y_pred_flat)\n",
    "        metrics.update(segment_metrics)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    @staticmethod\n",
    "    def segment_evaluation(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "        \"\"\"\n",
    "        Calculate segment evaluation metrics.\n",
    "        \"\"\"\n",
    "        segments = {\n",
    "            '0': (0, 0),\n",
    "            '0_50': (0, 50),\n",
    "            '50_100': (50, 100),\n",
    "            '100_above': (100, np.inf)\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for name, (lower, upper) in segments.items():\n",
    "            if lower == upper:\n",
    "                mask = y_true == lower\n",
    "            elif upper == np.inf:\n",
    "                mask = y_true > lower\n",
    "            else:\n",
    "                mask = (y_true > lower) & (y_true <= upper)\n",
    "                \n",
    "            y_true_seg = y_true[mask]\n",
    "            y_pred_seg = y_pred[mask]\n",
    "            \n",
    "            if len(y_true_seg) > 0:\n",
    "                results[f'MAE_{name}'] = mean_absolute_error(y_true_seg, y_pred_seg)\n",
    "                results[f'RMSE_{name}'] = mean_squared_error(y_true_seg, y_pred_seg, squared=False)\n",
    "            else:\n",
    "                results[f'MAE_{name}'] = np.nan\n",
    "                results[f'RMSE_{name}'] = np.nan\n",
    "                \n",
    "        return results\n",
    "\n",
    "# Example usage with your data:\n",
    "\n",
    "# Load the data\n",
    "#data = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\InterSim层次聚类后的Q料202001-202302(halfmonth).csv', index_col=0)\n",
    "#data = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\salestv_data.csv', index_col=0)\n",
    "data = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\carpartsdelete70.csv', index_col=0)\n",
    "# Convert to numpy array (excluding the first column which is the part number)\n",
    "ts_data = data.iloc[:, :].values\n",
    "\n",
    "# Split into train and test\n",
    "train_size = 47 #47 72 1909\n",
    "train_data = ts_data[:, :train_size]\n",
    "test_data = ts_data[:, train_size:]\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = CrostonModel(alpha=0.1)\n",
    "fitted_models = model.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(fitted_models, steps=test_data.shape[1])\n",
    "\n",
    "# Evaluate\n",
    "evaluator = CrostonEvaluator()\n",
    "metrics = evaluator.evaluate(test_data, predictions, train_data)\n",
    "\n",
    "# Print metrics\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R2': 0.6568023107026171,\n",
       " 'RMSE': 2.0999644899666943,\n",
       " 'RMSE_non_zero': 2.7744911195247357,\n",
       " 'MAE': 1.068019106486348,\n",
       " 'MAE_non_zero': 1.5565091770761292,\n",
       " 'MASE': 1.6605150204581687,\n",
       " 'MASE_non_zero': 2.610491334623011,\n",
       " 'RMSSE': 0.8201849585891773,\n",
       " 'RMSSE_non_zero': 1.1198853468089724,\n",
       " 'QuantileLoss_50': 0.7472769896049746,\n",
       " 'Precision': 0.0,\n",
       " 'Recall': 0.0,\n",
       " 'F1': 0.0,\n",
       " 'MAE_0': 0.662668797055579,\n",
       " 'RMSE_0': 1.2967272069859148,\n",
       " 'MAE_0_50': 1.5288567972707663,\n",
       " 'RMSE_0_50': 2.5943145864799333,\n",
       " 'MAE_50_100': 19.40204325171845,\n",
       " 'RMSE_50_100': 23.891746478071703,\n",
       " 'MAE_100_above': 39.3106244355605,\n",
       " 'RMSE_100_above': 47.38884605348456}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97982548, 0.97982548, 0.97982548, 0.97982548],\n",
       "       [0.20475479, 0.20475479, 0.20475479, 0.20475479],\n",
       "       [0.53870639, 0.53870639, 0.53870639, 0.53870639],\n",
       "       ...,\n",
       "       [0.99053972, 0.99053972, 0.99053972, 0.99053972],\n",
       "       [0.84887271, 0.84887271, 0.84887271, 0.84887271],\n",
       "       [1.93342931, 1.93342931, 1.93342931, 1.93342931]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Beta: 0.1, Forecast Value: 220.22\n",
      "Alpha: 0.1, Beta: 0.2, Forecast Value: 204.31\n",
      "Alpha: 0.1, Beta: 0.3, Forecast Value: 203.78\n",
      "Alpha: 0.2, Beta: 0.1, Forecast Value: 147.85\n",
      "Alpha: 0.2, Beta: 0.2, Forecast Value: 137.17\n",
      "Alpha: 0.2, Beta: 0.3, Forecast Value: 136.81\n",
      "Alpha: 0.3, Beta: 0.1, Forecast Value: 126.47\n",
      "Alpha: 0.3, Beta: 0.2, Forecast Value: 117.33\n",
      "Alpha: 0.3, Beta: 0.3, Forecast Value: 117.02\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 定义 Croston 方法\n",
    "def croston_forecast(data, alpha, beta):\n",
    "    non_zero_data = data[data > 0]\n",
    "    demand = np.mean(non_zero_data)\n",
    "    intervals = np.where(data > 0)[0]\n",
    "\n",
    "    if len(intervals) > 0:\n",
    "        interval_mean = np.mean(np.diff(intervals))\n",
    "    else:\n",
    "        interval_mean = 1  # 如果没有非零需求，设置为1\n",
    "\n",
    "    forecast_demand = demand\n",
    "    forecast_interval = interval_mean\n",
    "\n",
    "    for d in data:\n",
    "        if d > 0:\n",
    "            forecast_demand = alpha * d + (1 - alpha) * forecast_demand\n",
    "            forecast_interval = beta * (1) + (1 - beta) * forecast_interval\n",
    "\n",
    "    return forecast_demand * forecast_interval\n",
    "\n",
    "# 给定的时间序列数据\n",
    "data = np.array([100.0, 0.0, 0.0, 1200.0, 0.0, 3385.0, 388.0, 375.0,\n",
    "                 222.0, 155.0, 55.0, 0.0, 0.0, 0.0, 0.0, 87.0,\n",
    "                 0.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.902, 0.0,\n",
    "                 0.0, 0.0, 0.0, 60.0, 200.0, 538.0, 55.0,\n",
    "                 420.0, 540.0, 430.0, 605.0, 174.374, 128.0,\n",
    "                 0.0, 36.632, 0.0, 0.0, 50.0, 0.0, 60.0,\n",
    "                 0.0, 0.0, 247.91, 0.0, 50.0, 98.426, 27.97,\n",
    "                 0.0, 170.344, 0.0])\n",
    "\n",
    "# 不同的 alpha 和 beta 值\n",
    "alpha_values = [0.1, 0.2, 0.3]\n",
    "beta_values = [0.1, 0.2, 0.3]\n",
    "\n",
    "# 计算预测值\n",
    "results = {}\n",
    "for alpha in alpha_values:\n",
    "    for beta in beta_values:\n",
    "        forecast_value = croston_forecast(data, alpha, beta)\n",
    "        results[(alpha, beta)] = forecast_value\n",
    "\n",
    "# 输出结果\n",
    "for (alpha, beta), value in results.items():\n",
    "    print(f\"Alpha: {alpha}, Beta: {beta}, Forecast Value: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
