{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import*\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#中文显示问题\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# notebook嵌入图片\n",
    "%matplotlib inline\n",
    "# 提高分辨率\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# 切分数据\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 评价指标\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GluonTs包\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.model.wavenet import WaveNetEstimator\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.transformer import TransformerEstimator\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from gluonts.mx import Trainer\n",
    "import optuna\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "def mean_absolute_scaled_error(y_true, y_pred, y_train):\n",
    "    \"\"\"\n",
    "    计算平均绝对比例误差（MASE）\n",
    "    y_true: 测试集真实值\n",
    "    y_pred: 测试集预测值\n",
    "    y_train: 训练集真实值\n",
    "    \"\"\"\n",
    "    n = y_true.shape[0]\n",
    "    scaling_factor = np.mean(np.abs(np.diff(y_train)))\n",
    "    errors = np.abs(y_true - y_pred) / scaling_factor\n",
    "    return np.mean(errors)\n",
    "\n",
    "def root_mean_square_scaled_error(y_true, y_pred, y_train):\n",
    "    \"\"\"\n",
    "    计算平均绝对比例误差（RMSSE）\n",
    "    y_true: 测试集真实值\n",
    "    y_pred: 测试集预测值\n",
    "    y_train: 训练集真实值\n",
    "    \"\"\"\n",
    "    n = y_true.shape[0]\n",
    "    scaling_factor = np.mean(np.square(np.diff(y_train)))\n",
    "    errors = np.square(y_true - y_pred) / scaling_factor\n",
    "    return np.sqrt(np.mean(errors))\n",
    "\n",
    "def QuantileLoss(y, y_hat, rou):\n",
    "    # return 2 * (np.sum(y_hat) - np.sum(y)) * (rou * (np.sum(y_hat)>np.sum(y)) - (1-rou) * (np.sum(y_hat)<=np.sum(y)))\n",
    "    E = np.sum(y_hat) - np.sum(y)\n",
    "    return max(rou * E, (1-rou) * (-E))\n",
    "    #return 2 * np.sum(np.abs((y_hat - y) * ((y <= y_hat) - rou)))\n",
    "\n",
    "def BiasAmount(y, y_hat):\n",
    "    E = np.sum(y_hat) - np.sum(y)\n",
    "    return E\n",
    "\n",
    "def RMSSE(y, y_hat, x, h=1):\n",
    "    fenzi = np.sum(np.square(y - y_hat))\n",
    "    T = len(x)\n",
    "\n",
    "    fenmu = 0.0\n",
    "    for t in range(1, T):\n",
    "        fenmu += (x[t] - x[t-1])**2\n",
    "    fenmu = fenmu / (T-1)\n",
    "\n",
    "    RMSSE = np.sqrt(fenzi / (fenmu * h))\n",
    "    return RMSSE\n",
    "\n",
    "def Segment_MAE(test_y, test_predict):\n",
    "    test_y_0 = []\n",
    "    test_predict_0 = []\n",
    "    test_y_0_50 = []\n",
    "    test_predict_0_50 = []\n",
    "    test_y_50_100 = []\n",
    "    test_predict_50_100 = []\n",
    "    test_y_100_above = []\n",
    "    test_predict_100_above = []\n",
    "\n",
    "    for i in range(len(test_y)):\n",
    "        if test_y[i] == 0:\n",
    "            test_y_0.append(test_y[i])\n",
    "            test_predict_0.append(test_predict[i])\n",
    "        elif test_y[i] > 0 and test_y[i] <= 50:\n",
    "            test_y_0_50.append(test_y[i])\n",
    "            test_predict_0_50.append(test_predict[i])\n",
    "        elif test_y[i] > 50 and test_y[i] <= 100:\n",
    "            test_y_50_100.append(test_y[i])\n",
    "            test_predict_50_100.append(test_predict[i])\n",
    "        elif test_y[i] > 100:\n",
    "            test_y_100_above.append(test_y[i])\n",
    "            test_predict_100_above.append(test_predict[i])\n",
    "\n",
    "    RMSE_0 = mean_absolute_error(test_y_0, test_predict_0)\n",
    "    print('0RMSE:%f' % (RMSE_0))\n",
    "    RMSE_0_50 = mean_absolute_error(test_y_0_50, test_predict_0_50)\n",
    "    print('0-50RMSE值:%f' % (RMSE_0_50))\n",
    "    RMSE_50_100 = mean_absolute_error(test_y_50_100, test_predict_50_100)\n",
    "    print('50-100RMSE值:%f' % (RMSE_50_100))\n",
    "    RMSE_100_above = mean_absolute_error(test_y_100_above, test_predict_100_above)\n",
    "    print('>100RMSE值:%f' % (RMSE_100_above))\n",
    "\n",
    "    ##保存各个分段的真实值和预测值\n",
    "    # df_0 = pd.DataFrame({'test_y':test_y_0, 'test_predict':test_predict_0})\n",
    "    # df_0.to_csv('../predict_result(半月数据InterSim聚类的477SKU)/DeepAR(混合分布2LSTM+2Normal+1NormalMixture)分段结果/DeepAR(混合分布)_0.csv',index=False)\n",
    "    #\n",
    "    # df_0_50 = pd.DataFrame({'test_y':test_y_0_50, 'test_predict':test_predict_0_50})\n",
    "    # df_0_50.to_csv('../predict_result(半月数据InterSim聚类的477SKU)/DeepAR(混合分布2LSTM+2Normal+1NormalMixture)分段结果/DeepAR(混合分布)_0_50.csv',index=False)\n",
    "    #\n",
    "    # df_50_100 = pd.DataFrame({'test_y':test_y_50_100, 'test_predict':test_predict_50_100})\n",
    "    # df_50_100.to_csv('../predict_result(半月数据InterSim聚类的477SKU)/DeepAR(混合分布2LSTM+2Normal+1NormalMixture)分段结果/DeepAR(混合分布)_50_100.csv',index=False)\n",
    "    #\n",
    "    # df_100_above = pd.DataFrame({'test_y':test_y_100_above, 'test_predict':test_predict_100_above})\n",
    "    # df_100_above.to_csv('../predict_result(半月数据InterSim聚类的477SKU)/DeepAR(混合分布2LSTM+2Normal+1NormalMixture)分段结果/DeepAR(混合分布)_100_above.csv',index=False)\n",
    "\n",
    "def Segment_RMSE(test_y, test_predict):\n",
    "    test_y_0 = []\n",
    "    test_predict_0 = []\n",
    "    test_y_0_50 = []\n",
    "    test_predict_0_50 = []\n",
    "    test_y_50_100 = []\n",
    "    test_predict_50_100 = []\n",
    "    test_y_100_above = []\n",
    "    test_predict_100_above = []\n",
    "\n",
    "    for i in range(len(test_y)):\n",
    "        if test_y[i] == 0:\n",
    "            test_y_0.append(test_y[i])\n",
    "            test_predict_0.append(test_predict[i])\n",
    "        elif test_y[i] > 0 and test_y[i] <= 50:\n",
    "            test_y_0_50.append(test_y[i])\n",
    "            test_predict_0_50.append(test_predict[i])\n",
    "        elif test_y[i] > 50 and test_y[i] <= 100:\n",
    "            test_y_50_100.append(test_y[i])\n",
    "            test_predict_50_100.append(test_predict[i])\n",
    "        elif test_y[i] > 100:\n",
    "            test_y_100_above.append(test_y[i])\n",
    "            test_predict_100_above.append(test_predict[i])\n",
    "\n",
    "    RMSE_0 = mean_squared_error(test_y_0, test_predict_0, squared=False)\n",
    "    print('0RMSE:%f' % (RMSE_0))\n",
    "    RMSE_0_50 = mean_squared_error(test_y_0_50, test_predict_0_50, squared=False)\n",
    "    print('0-50RMSE值:%f' % (RMSE_0_50))\n",
    "    RMSE_50_100 = mean_squared_error(test_y_50_100, test_predict_50_100, squared=False)\n",
    "    print('50-100RMSE值:%f' % (RMSE_50_100))\n",
    "    RMSE_100_above = mean_squared_error(test_y_100_above, test_predict_100_above, squared=False)\n",
    "    print('>100RMSE值:%f' % (RMSE_100_above))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Part  Jan-98  Feb-98  Mar-98  Apr-98  May-98  Jun-98  Jul-98  Aug-98  \\\n",
      "0    21053055       1       0       0       0       0       1       0       0   \n",
      "1    21091739       1       2       0       1       0       0       1       0   \n",
      "2    21314374       0       0       0       0       0       0       0       0   \n",
      "3    21068915       0       1       0       0       1       0       2       0   \n",
      "4    21313797       0       0       0       0       0       0       0       0   \n",
      "..        ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "852  21059522       6       6       5       0       2       1       3       1   \n",
      "853  21017605       6       5       5       3       5       0       2       1   \n",
      "854  21055552      11       2       0       2      12       0       0       4   \n",
      "855  21311629       0       0       0       2       1       0       2       4   \n",
      "856  21311636       0       0       0       0       2       4       4       1   \n",
      "\n",
      "     Sep-98  ...  Jun-01  Jul-01  Aug-01  Sep-01  Oct-01  Nov-01  Dec-01  \\\n",
      "0         0  ...       0       0       0       0       0       0       0   \n",
      "1         0  ...       0       0       0       1       0       0       0   \n",
      "2         0  ...       0       0       1       1       1       0       0   \n",
      "3         0  ...       0       0       0       0       0       0       0   \n",
      "4         0  ...       0       1       0       1       1       1       0   \n",
      "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "852       5  ...       1       0       1       0       2       0       1   \n",
      "853       3  ...       0       0       0       0       0       0       0   \n",
      "854       2  ...       0       0       0       0       1       1       2   \n",
      "855       2  ...       0       0       4       0       1       2       2   \n",
      "856       4  ...       1       0       1       0       0       2       2   \n",
      "\n",
      "     Jan-02  Feb-02  Mar-02  \n",
      "0         0       2       2  \n",
      "1         0       1       1  \n",
      "2         0       1       0  \n",
      "3         0       0       0  \n",
      "4         1       1       0  \n",
      "..      ...     ...     ...  \n",
      "852       0       3       0  \n",
      "853       0       1       0  \n",
      "854       1       2       0  \n",
      "855       3       1       3  \n",
      "856       0       1       1  \n",
      "\n",
      "[857 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "读取数据集\n",
    "'''\n",
    "df = pd.read_csv('E:/ZIP-DeepAR代码/data/carpartsdelete70.csv', header=0)\n",
    "#df = pd.read_csv('E:/ZIP-DeepAR代码/data/carpartsdeletepick.csv', header=0)\n",
    "#df = pd.read_csv('E:/ZIP-DeepAR代码/data/carpartsdelete80.csv', header=0)\n",
    "#df = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\InterSim层次聚类后的Q料202001-202302(halfmonth).csv', header=0)\n",
    "#df = pd.read_csv('E:\\ZIP-DeepAR代码\\data\\salestv_data.csv', header=0)\n",
    "print(df)\n",
    "#id_1913 = df['id'].values.tolist()\n",
    "#df = df.drop('id',axis=1)\n",
    "#sku_477 = df['sku'].values.tolist()\n",
    "#df = df.drop('sku',axis=1)\n",
    "Parts_2509 = df['Part'].values.tolist()\n",
    "df = df.drop('Part',axis=1)\n",
    "\n",
    "\n",
    "#将列名转化为202001 ~ 202604月份，避免freq=15d的2-30日期问题\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "date_str = '1998-01'\n",
    "date_format = '%Y-%m'\n",
    "num_months = 51\n",
    "\n",
    "dates = []\n",
    "current_date = datetime.strptime(date_str, date_format)\n",
    "\n",
    "for i in range(num_months):\n",
    "    dates.append(current_date.strftime(date_format))\n",
    "    num_days = calendar.monthrange(current_date.year, current_date.month)[1]\n",
    "    current_date += timedelta(days=num_days)\n",
    "\n",
    "df.columns = dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(857,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 2 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 2 1 1 0 0 1 0 0 0 0 0 0 1 0 0 2 1 0 2 0 0 0 1 2 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 2 0 0 0 1 0 0 0 0 0 0 0 2 0 1 1 0 0 2 0 0 0 2 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 4 0 1 2 6 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 2 0 2 2 2 1 0 0 0 0 1 0 0 1 1 0 0 1 2 1 0 0 4 0 0 2 0 0 0 0 0 0 2 0\n",
      " 0 0 0 0 0 0 1 0 1 0 2 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 2 1 0 1 1 0 0\n",
      " 0 1 2 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0\n",
      " 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 5 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 4 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 3 4 2 0 0 1 4 0 0\n",
      " 2 0 0 1 0 1 0 2 0 0 0 2 1 0 0 1 1 1 0 0 1 0 2 1 1 0 0 1 1 0 0 0 0 0 2 0 0\n",
      " 3 0 2 0 0 0 0 0 0 1 3 0 2 0 1 0 0 0 2 0 0 0 2 0 0 0 1 1 0 0 0 1 0 3 0 0 0\n",
      " 0 0 2 0 1 0 0 0 0 0 0 1 2 0 1 3 0 1 1 0 0 0 0 2 0 2 0 0 0 0 2 1 1 2 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 0\n",
      " 1 0 0 0 4 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 2 0 0 0 3 1 0 2 0 1 0 1 0 0 0\n",
      " 0 3 0 0 0 0 1 0 0 1 0 0 0 0 2 0 0 0 0 0 1 2 1 2 0 3 0 1 0 0 8 0 0 0 0 0 0\n",
      " 0 0 4 0 3 0 2 0 0 0 1 0 2 0 0 0 0 0 1 0 0 0 2 0 2 1 0 1 1 1 0 2 0 1 1 1 1\n",
      " 3 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 6 0 3 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 2 1 2 0 0 0 2 0 2 2 0 0 2 0 0 1 0 4 0 1 2 1 0 0 0 2 0 1\n",
      " 2 0 0 1 0 0 1 2 0 0 2 0 2 0 1 0 2 1 0 0 0 0 0 1 0 1 2 0 0 4 0 1 3 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 2 0 0 2 0 0 0 0 0 2 1 2 2 0 0 1 1 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 4 0 0 0 0 0 1 1 1 1 0 0 5 0 1 0 0 0 1 4 0 0 0 2 0 0 0\n",
      " 0 1 0 2 2 2]\n",
      "[1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 3 1 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 1 2 1 1 2\n",
      " 2 1 1 1 4 1 2 6 1 1 2 2 2 2 1 1 1 1 1 2 1 4 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1\n",
      " 2 1 1 1 1 1 2 2 2 1 1 1 1 1 1 5 1 1 1 4 1 1 1 3 4 2 1 4 2 1 1 2 2 1 1 1 1\n",
      " 1 2 1 1 1 1 2 3 2 1 3 2 1 2 2 1 1 1 3 2 1 1 2 1 3 1 1 2 2 2 1 1 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 2 3 1 2 1 1 3 1 1 2 1 2 1 2 3 1 8 4\n",
      " 3 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 3 2 1 1 1 1 1 6 3 1 2 1 2 2 2 2 2 1 4 1 2\n",
      " 1 2 1 2 1 1 2 2 2 1 2 1 1 1 2 4 1 3 1 1 1 2 2 2 1 2 2 1 1 1 1 1 1 1 4 1 1\n",
      " 1 1 5 1 1 4 2 1 2 2 2]\n",
      "857\n",
      "\n",
      "第857个单步预测时间点的测试集大小(样本数)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "构造训练集、测试集\n",
    "'''\n",
    "##提取test_y\n",
    "test_y = []\n",
    "for x in df.values:\n",
    "    test_y.append(x[-4])\n",
    "test_y = np.array(test_y)\n",
    "test_y = test_y.reshape(-1)\n",
    "print(test_y.shape)\n",
    "print(test_y)\n",
    "zero_mask = test_y == 0\n",
    "non_zero_mask = ~zero_mask\n",
    "test_y_non_zero = test_y[non_zero_mask]\n",
    "print(test_y_non_zero)\n",
    "train_series_list = []\n",
    "for i in range(df.shape[0]):\n",
    "    train_series = df.iloc[i, :-4].values  # 假设最后4个点是测试点\n",
    "    train_series_list.append(train_series)\n",
    "train_series_non_zero = [train_series_list[i] for i in range(len(test_y)) if non_zero_mask[i]]\n",
    "\n",
    "train_list = []\n",
    "prod_sales_max = []\n",
    "index = 0\n",
    "\n",
    "\n",
    "for i in range(df.shape[0]):  #构造训练集，每个产品的前72个半月的销量  （[第1个产品的前72个半月的销量，第2个产品的前72个半月的销量,...])\n",
    "   dic = {'month':df.columns, 'sales':df.iloc[i].values}\n",
    "   prod_data = pd.DataFrame(dic)\n",
    "   prod_data.reset_index(inplace=True)\n",
    "\n",
    "   #对数变换\n",
    "   prod_data['sales'] = np.log(prod_data['sales']+1)\n",
    "\n",
    "   # # 数据归一化\n",
    "   # prod_data['sales'] = (prod_data['sales'] - np.min(prod_data['sales'])) / (np.max(prod_data['sales']) - np.min(prod_data['sales']))\n",
    "\n",
    "   train_dic = {\"start\": prod_data.iloc[0]['month'], \"target\": prod_data.iloc[0:47]['sales']}\n",
    "   train_list.append(train_dic)\n",
    "training_data = ListDataset(train_list, freq=\"1m\") #输入数据格式\n",
    "print(len(training_data))\n",
    "print()\n",
    "\n",
    "###构造测试集，每个产品的第73~76个月的销量\n",
    "### 为h个单步预测时间点，分别构建h个ListDataset测试集\n",
    "test_data_list = []\n",
    "for predict_day in range(48, 49): #需要单步预测的时间点（使用前t-1时间点的真实值，来预测第t个时间点的预测值)\n",
    "    test_list = []\n",
    "    for i in range(df.shape[0]):\n",
    "        dic = {'month': df.columns, 'sales': df.iloc[i].values}\n",
    "        prod_data = pd.DataFrame(dic)\n",
    "        prod_data.reset_index(inplace=True)\n",
    "\n",
    "        # 对数变换\n",
    "        prod_data['sales'] = np.log(prod_data['sales'] + 1)\n",
    "        test_dic = {\"start\": prod_data.iloc[0]['month'], \"target\": prod_data.iloc[0:predict_day]['sales']} ###dict修改成predict_length=1的形式\n",
    "\n",
    "        # # 数据归一化\n",
    "        # test_dic['target'] = (test_dic['target'] - np.min(test_dic['target'])) / (np.max(test_dic['target']) - np.min(test_dic['target']))\n",
    "        # # 每条测试样本对应的最大最小值\n",
    "        # max_values.append(np.max(test_dic['target']))\n",
    "        # min_values.append(np.min(test_dic['target']))\n",
    "        test_list.append(test_dic)\n",
    "    test_data = ListDataset(test_list, freq=\"1m\")\n",
    "    print('第%d个单步预测时间点的测试集大小(样本数)'%len(test_data))\n",
    "\n",
    "    test_data_list.append(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####模型训练####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 100/100 [00:03<00:00, 30.45it/s, epoch=1/15, avg_epoch_loss=1.11]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:03<00:00, 32.82it/s, epoch=2/15, avg_epoch_loss=0.981]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:03<00:00, 32.12it/s, epoch=3/15, avg_epoch_loss=0.937]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:03<00:00, 32.50it/s, epoch=4/15, avg_epoch_loss=0.948]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:03<00:00, 32.09it/s, epoch=5/15, avg_epoch_loss=0.925]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:03<00:00, 32.90it/s, epoch=6/15, avg_epoch_loss=0.974]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:03<00:00, 32.95it/s, epoch=7/15, avg_epoch_loss=0.994]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:03<00:00, 32.37it/s, epoch=8/15, avg_epoch_loss=0.991]\n",
      "100%|██████████████████████████████████████████████| 100/100 [00:03<00:00, 32.89it/s, epoch=9/15, avg_epoch_loss=0.927]\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:03<00:00, 29.74it/s, epoch=10/15, avg_epoch_loss=0.969]\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:03<00:00, 30.65it/s, epoch=11/15, avg_epoch_loss=0.972]\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:02<00:00, 33.35it/s, epoch=12/15, avg_epoch_loss=0.922]\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:03<00:00, 31.78it/s, epoch=13/15, avg_epoch_loss=0.923]\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:03<00:00, 31.94it/s, epoch=14/15, avg_epoch_loss=0.949]\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:03<00:00, 33.24it/s, epoch=15/15, avg_epoch_loss=0.941]\n"
     ]
    }
   ],
   "source": [
    "print('####模型训练####')\n",
    "context_l = 24\n",
    "estimator = TransformerEstimator(freq = 'M',\n",
    "                            prediction_length = 1,\n",
    "                            trainer=Trainer(epochs=15,num_batches_per_epoch=100,learning_rate=5e-2),\n",
    "                             ) \n",
    "                            \n",
    "predictor = estimator.train(training_data=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mxnet as mx\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "'''\n",
    "模型批量测试\n",
    "'''\n",
    "##预测阈值(小于阈值记为0)\n",
    "predict_threshold = 1\n",
    "zero_prob_threshold = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining time series conditioning values ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 857/857 [00:00<00:00, 2629.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining time series predictions ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 857/857 [00:02<00:00, 354.11it/s]\n"
     ]
    }
   ],
   "source": [
    "## 初始化结果容器\n",
    "test_predict_non_zero = []\n",
    "\n",
    "test_predict_non_zero_alltime = []\n",
    "test_predict_10_alltime = []\n",
    "test_predict_50_alltime = []\n",
    "test_predict_90_alltime = []\n",
    "test_predict_means_alltime = []\n",
    "\n",
    "for test_data in test_data_list:\n",
    "    # 生成预测\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_data,\n",
    "        predictor=predictor,\n",
    "        num_samples=100\n",
    "    )\n",
    "\n",
    "    print(\"Obtaining time series conditioning values ...\")\n",
    "    tss = list(tqdm(ts_it, total=len(test_data)))\n",
    "\n",
    "    print(\"Obtaining time series predictions ...\")\n",
    "    forecasts = list(tqdm(forecast_it, total=len(test_data)))\n",
    "\n",
    "    # 提取预测值（直接基于 prediction 对象）\n",
    "    test_predict = []\n",
    "    test_predict_alltime = []\n",
    "    test_predict_10 = []\n",
    "    test_predict_50 = []\n",
    "    test_predict_90 = []\n",
    "    test_predict_means = []\n",
    "    for i in range(len(forecasts)): #1个list\n",
    "        prediction = forecasts[i] #每个样本的预测输出结果: 预测值+分布参数\n",
    "\n",
    "        prediction_means = np.array(list(prediction.mean))[0]\n",
    "        prediction_array = np.array(list(prediction.samples))\n",
    "        prediction_non_zero = np.mean(prediction_array[prediction_array != 0]) if np.any(prediction_array != 0) else 0.0\n",
    "        # 计算分位数\n",
    "        prediction_10 = np.percentile(prediction_array, 10)\n",
    "        prediction_50 = np.percentile(prediction_array, 50)\n",
    "        prediction_90 = np.percentile(prediction_array, 90)\n",
    "\n",
    "        # 对数变换还原\n",
    "        prediction_means = np.exp(prediction_means) - 1\n",
    "        prediction_non_zero = np.exp(prediction_non_zero) - 1\n",
    "        prediction_10 = np.exp(prediction_10) - 1\n",
    "        \n",
    "        prediction_50 = np.exp(prediction_50) - 1\n",
    "        prediction_90 = np.exp(prediction_90) - 1\n",
    "        \n",
    "        #if prediction_means < predict_threshold:\n",
    "        #    prediction_means = 0.0\n",
    "\n",
    "        test_predict.append(prediction_means)\n",
    "        test_predict_non_zero_alltime.append(test_predict_non_zero)\n",
    "        test_predict_10.append(prediction_10)\n",
    "        test_predict_50.append(prediction_50)\n",
    "        test_predict_90.append(prediction_90)\n",
    "        test_predict_means.append(prediction_means)\n",
    "        \n",
    "    test_predict_alltime.append(test_predict)\n",
    "    test_predict_non_zero.append(prediction_non_zero)\n",
    "    test_predict_10_alltime.append(test_predict_10)\n",
    "    test_predict_50_alltime.append(test_predict_50)\n",
    "    test_predict_90_alltime.append(test_predict_90)\n",
    "    test_predict_means_alltime.append(prediction_means)\n",
    "    \n",
    "# 结果整理\n",
    "test_predict = np.array(test_predict_alltime)\n",
    "test_predict = np.transpose(test_predict).reshape(-1)\n",
    "\n",
    "test_predict_non_zero = np.array(test_predict_non_zero_alltime) #(单步预测的时间数，时间序列SKU数)\n",
    "test_predict_non_zero = np.transpose(test_predict_non_zero).reshape(-1) #(时间序列SKU数, 单步预测的时间数)\n",
    "\n",
    "test_predict_10 = np.array(test_predict_10_alltime)\n",
    "test_predict_10 = np.transpose(test_predict_10).reshape(-1)\n",
    "\n",
    "test_predict_50 = np.array(test_predict_50_alltime)\n",
    "test_predict_50 = np.transpose(test_predict_50).reshape(-1)\n",
    "\n",
    "test_predict_90 = np.array(test_predict_90_alltime)\n",
    "test_predict_90 = np.transpose(test_predict_90).reshape(-1)\n",
    "\n",
    "test_predict_means = np.array(test_predict_means_alltime)\n",
    "test_predict_means = np.transpose(test_predict_means).reshape(-1)\n",
    "\n",
    "# 保存预测结果\n",
    "#df_test_predict = pd.DataFrame({'test_y': test_y, 'test_predict': test_predict})\n",
    "#df_test_predict.to_csv('预测结果.csv', index=False)\n",
    "#print(\"预测结果已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####模型评估####\n",
      "R2值：-0.116629\n",
      "RMSE值:0.974102\n",
      "RMSE_non_zero值:1.578469\n",
      "MAE值:0.612545\n",
      "MAE_non_zero值:1.230718\n",
      "MASE1:0.629422\n",
      "MASE_non_zero: 1.684529\n",
      "RMSSE1:0.400968\n",
      "RMSSE2:0.400968\n",
      "RMSSE_non_zero: 1.060116\n",
      "L=0,S=1,rou=10%时的QuantileLoss值：0.290806\n",
      "\n",
      "L=0,S=1,rou=50%时的QuantileLoss值：1.203281\n",
      "\n",
      "L=0,S=1,rou=50%时的QuantileLossprdm值：1.226522\n",
      "\n",
      "L=0,S=1,rou=90%时的QuantileLoss值：1.303934\n",
      "\n",
      "Precision值:0.000000\n",
      "Recall值:0.000000\n",
      "F1-Score值:0.000000\n",
      "0RMSE:0.328207\n",
      "0-50RMSE值:1.230718\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bc8c6fee8899>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;31m##分段RMSE指标\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m \u001b[0mSegment_MAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[0mSegment_RMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-aaa5a489cfda>\u001b[0m in \u001b[0;36mSegment_MAE\u001b[1;34m(test_y, test_predict)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mRMSE_0_50\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y_0_50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict_0_50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0-50RMSE值:%f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mRMSE_0_50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mRMSE_50_100\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y_50_100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict_50_100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'50-100RMSE值:%f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mRMSE_50_100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mRMSE_100_above\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y_100_above\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict_100_above\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \"\"\"\n\u001b[0;32m    182\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 183\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \"\"\"\n\u001b[0;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    727\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[1;32m--> 729\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "'''\n",
    "四、模型评估\n",
    "'''\n",
    "print('####模型评估####')\n",
    "testmonth_num = 1 #预测区间时间点的数量（大于1不代表一定是多步预测，也可以是单步预测）\n",
    "test_y_non_zero = []\n",
    "test_predict_non_zero = []\n",
    "for y_true, y_pred in zip(test_y, test_predict):\n",
    "    if y_true != 0:  # 只保留实际值非零的预测对\n",
    "        test_y_non_zero.append(y_true)\n",
    "        test_predict_non_zero.append(y_pred)\n",
    "##R2指标\n",
    "Rsquare = r2_score(test_y, test_predict)\n",
    "print('R2值：%f'%(Rsquare))\n",
    "\n",
    "##RMSE指标\n",
    "RMSE = mean_squared_error(test_y, test_predict, squared=False)\n",
    "print('RMSE值:%f'%(RMSE))\n",
    "\n",
    "RMSE_non_zero = mean_squared_error(test_y_non_zero, test_predict_non_zero, squared=False)\n",
    "print('RMSE_non_zero值:%f'%(RMSE_non_zero))\n",
    "\n",
    "##MAE指标\n",
    "MAE = mean_absolute_error(test_y, test_predict)\n",
    "MAE_non_zero = mean_absolute_error(test_y_non_zero, test_predict_non_zero)\n",
    "print('MAE值:%f'%(MAE))\n",
    "print('MAE_non_zero值:%f'%(MAE_non_zero))\n",
    "\n",
    "##MASE指标\n",
    "MASE1 = 0.0\n",
    "num = int(len(test_y)/testmonth_num)\n",
    "for i in range(num):\n",
    "    MASE1 += mean_absolute_scaled_error(test_y[(testmonth_num*i):(testmonth_num*i+testmonth_num)], test_predict[(testmonth_num*i):(testmonth_num*i+testmonth_num)], df.iloc[i, 0:-4].values)\n",
    "MASE1 = MASE1 / num\n",
    "print('MASE1:%f' % (MASE1))\n",
    "\n",
    "MASE_non_zero = 0.0\n",
    "num = int(len(test_y_non_zero)/testmonth_num)\n",
    "for i in range(num):\n",
    "    y_true_segment = np.array(test_y_non_zero[(testmonth_num * i):(testmonth_num * i + testmonth_num)])\n",
    "    y_pred_segment = np.array(test_predict_non_zero[(testmonth_num * i):(testmonth_num * i + testmonth_num)])\n",
    "\n",
    "    MASE_non_zero += mean_absolute_scaled_error(\n",
    "        y_true_segment,\n",
    "        y_pred_segment,\n",
    "        df.iloc[i, 0:-4].values\n",
    "    )\n",
    "\n",
    "MASE_non_zero /= num\n",
    "print('MASE_non_zero: %f' % MASE_non_zero)\n",
    "\n",
    "# MASE2 = mean_absolute_scaled_error(test_y, test_predict, df.iloc[:, 0:-4].values)\n",
    "# print('MASE2:%f' % (MASE2))\n",
    "\n",
    "\n",
    "##RMSSE指标\n",
    "'''\n",
    "RMSSE指标\n",
    "'''\n",
    "RMSSE_value = 0.0\n",
    "num = int(len(test_y)/testmonth_num)\n",
    "for i in range(num):\n",
    "    RMSSE_value += root_mean_square_scaled_error(test_y[(testmonth_num*i):(testmonth_num*i+testmonth_num)], test_predict[(testmonth_num*i):(testmonth_num*i+testmonth_num)], df.iloc[i, 0:-4].values)\n",
    "RMSSE_value = RMSSE_value / num\n",
    "print('RMSSE1:%f' % (RMSSE_value))\n",
    "\n",
    "RMSSE_value2 = 0.0\n",
    "num = int(len(test_y)/testmonth_num)\n",
    "for i in range(num):\n",
    "    RMSSE_value2 += RMSSE(test_y[(testmonth_num*i):(testmonth_num*i+testmonth_num)], test_predict[(testmonth_num*i):(testmonth_num*i+testmonth_num)], df.iloc[i, 0:-4].values, h=testmonth_num)\n",
    "RMSSE_value2 = RMSSE_value2 / num\n",
    "print('RMSSE2:%f' % (RMSSE_value2))\n",
    "\n",
    "RMSSE_non_zero = 0.0\n",
    "num = int(len(test_y_non_zero)/testmonth_num)\n",
    "RMSSE_non_zero = 0.0\n",
    "\n",
    "for i in range(num):\n",
    "    y_true_segment = np.array(test_y_non_zero[(testmonth_num * i):(testmonth_num * i + testmonth_num)])\n",
    "    y_pred_segment = np.array(test_predict_non_zero[(testmonth_num * i):(testmonth_num * i + testmonth_num)])\n",
    "\n",
    "    RMSSE_non_zero += RMSSE(\n",
    "        y_true_segment,\n",
    "        y_pred_segment,\n",
    "        df.iloc[i, 0:-4].values,\n",
    "        h=testmonth_num\n",
    "    )\n",
    "\n",
    "RMSSE_non_zero /= num\n",
    "print('RMSSE_non_zero: %f' % RMSSE_non_zero)\n",
    "\n",
    "##QuantileLoss指标\n",
    "from gluonts.evaluation.metrics import quantile_loss\n",
    "LS_list = [(0,1)]  #L表示相对于第1个预测时间t0的QuantileLoss区间起始点，S表示QuantileLoss区间长度\n",
    "for LS_pair in LS_list:\n",
    "    L = LS_pair[0]\n",
    "    S = LS_pair[1]\n",
    "    QuantileLoss2 = 0.0\n",
    "    test_y2 = 0.0\n",
    "    num = int(len(test_y) / testmonth_num)  ##时间序列sku数量\n",
    "    for i in range(num):\n",
    "        QuantileLoss2 += quantile_loss(test_y[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                      test_predict_10[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                      q=0.1)\n",
    "        test_y2 += np.sum(test_y[(testmonth_num * i + L):(testmonth_num * i + L + S)])\n",
    "    #print(QuantileLoss2,test_y2)\n",
    "    QuantileLoss2 = QuantileLoss2 / test_y2\n",
    "    print('L=%d,S=%d,rou=10%%时的QuantileLoss值：%f' % (L,S,QuantileLoss2))\n",
    "print()\n",
    "for LS_pair in LS_list:\n",
    "    L = LS_pair[0]\n",
    "    S = LS_pair[1]\n",
    "    QuantileLoss2 = 0.0\n",
    "    test_y2 = 0.0\n",
    "    num = int(len(test_y) / testmonth_num)  ##时间序列sku数量\n",
    "    for i in range(num):\n",
    "        QuantileLoss2 += quantile_loss(test_y[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                      test_predict_50[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                      q=0.5)\n",
    "        test_y2 += np.sum(test_y[(testmonth_num * i + L):(testmonth_num * i + L + S)])\n",
    "    #print(QuantileLoss2,test_y2)\n",
    "    QuantileLoss2 = QuantileLoss2 / test_y2\n",
    "    print('L=%d,S=%d,rou=50%%时的QuantileLoss值：%f' % (L,S,QuantileLoss2))\n",
    "print()\n",
    "for LS_pair in LS_list:\n",
    "    L = LS_pair[0]\n",
    "    S = LS_pair[1]\n",
    "    QuantileLoss2 = 0.0\n",
    "    test_y2 = 0.0\n",
    "    num = int(len(test_y) / testmonth_num)  ##时间序列sku数量\n",
    "    for i in range(num):\n",
    "        QuantileLoss2 += quantile_loss(test_y[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                      test_predict[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                      q=0.5)\n",
    "        test_y2 += np.sum(test_y[(testmonth_num * i + L):(testmonth_num * i + L + S)])\n",
    "    #print(QuantileLoss2,test_y2)\n",
    "    QuantileLoss2 = QuantileLoss2 / test_y2\n",
    "    print('L=%d,S=%d,rou=50%%时的QuantileLossprdm值：%f' % (L,S,QuantileLoss2))\n",
    "print()\n",
    "for LS_pair in LS_list:\n",
    "    L = LS_pair[0]\n",
    "    S = LS_pair[1]\n",
    "    QuantileLoss2 = 0.0\n",
    "    test_y2 = 0.0\n",
    "    num = int(len(test_y) / testmonth_num)  ##时间序列sku数量\n",
    "    for i in range(num):\n",
    "        QuantileLoss2 += quantile_loss(test_y[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                      test_predict_90[(testmonth_num * i + L):(testmonth_num * i + L + S)],\n",
    "                                      q=0.9)\n",
    "        3\n",
    "        test_y2 += np.sum(test_y[(testmonth_num * i + L):(testmonth_num * i + L + S)])\n",
    "    #print(QuantileLoss2,test_y2)\n",
    "    QuantileLoss2 = QuantileLoss2 / test_y2\n",
    "    print('L=%d,S=%d,rou=90%%时的QuantileLoss值：%f' % (L,S,QuantileLoss2))\n",
    "print()\n",
    "\n",
    "##Zero精确率、召回率、F1-Score\n",
    "test_y_01 = [1 if x == 0 else 0 for x in test_y] #0为正类，1为负类\n",
    "test_predict_01 = [1 if x == 0 else 0 for x in test_predict]\n",
    "precision = precision_score(test_y_01, test_predict_01)\n",
    "recall = recall_score(test_y_01, test_predict_01)\n",
    "f1score = f1_score(test_y_01, test_predict_01)\n",
    "print('Precision值:%f'%(precision))\n",
    "print('Recall值:%f'%(recall))\n",
    "print('F1-Score值:%f'%(f1score))\n",
    "\n",
    "##分段RMSE指标\n",
    "Segment_MAE(test_y, test_predict)\n",
    "Segment_RMSE(test_y, test_predict)\n",
    "\n",
    "\n",
    "train_series_non_zero = [train_series_list[i] for i in range(len(train_series_list)) if non_zero_mask[i]]\n",
    "\n",
    "# Calculate non-zero MASE\n",
    "non_zero_mase_values = [mean_absolute_scaled_error(a, p, t)\n",
    "                       for a, p, t in zip(test_y_non_zero, test_predict_non_zero, train_series_non_zero)]\n",
    "print(f'Non-zero MASE: {np.nanmean(non_zero_mase_values):.4f}')\n",
    "\n",
    "# Calculate non-zero RMSSE\n",
    "non_zero_rmsse_values = [root_mean_square_scaled_error(a, p, t)\n",
    "                        for a, p, t in zip(test_y_non_zero, test_predict_non_zero, train_series_non_zero)]\n",
    "print(f'Non-zero RMSSE: {np.nanmean(non_zero_rmsse_values):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
